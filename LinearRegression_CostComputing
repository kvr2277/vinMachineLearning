% Can be used directly in Octave software
% X - denotes the feature details, as a matrix of features (columns) and number of training samples (m) , in training examples
% y - denotes vector of actual values in training examples
% theta - is weight assigned to each feature, theta is also called as parameter. Since each feature has different significance in 
predicting y, each weight assigned to parameter is different

% Below function J calculates the cost of prediction - cost is the error margin of prediction vs actual. Lower the cost, better our 
prediction

function J = computeCost(X, y, theta)
   %COMPUTECOST Compute cost for linear regression
   %   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the
   %   parameter for linear regression to fit the data points in X and y

   % Initialize some useful values
   m = length(y); % number of training examples
   J = 0;

   predictions = X*theta; 
   sqrErrors = (predictions - y).^2; 
   J = 1/(2*m)  * sum(sqrErrors);
end
